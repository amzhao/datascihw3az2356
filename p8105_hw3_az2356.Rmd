---
title: "p8105_hw2_az2356"
author: "Amelia Zhao"
date: "9/19/2019"
output: github_document
---
# This is my markdown file for Homework 3.


# Problem 1. 

Loading the instacart data & looking at the contents & structure:
```{r}
library(tidyverse)
library(p8105.datasets)
library(ggplot2)
library(devtools)
install_github("thomasp85/patchwork")
library(patchwork)
data("instacart")

instacart %>% 
  group_by(aisle) %>% 
  summarize(orders = n())
```
The instacart file contains data on orders for 49,688 grocery products, from 206,209 users. The data set can be easily viewed sorting by order IDs, user IDs, or product IDs for ease of access. 

For each user and their respective order(s), there is information on the order in which they added products to their cart, whether a product is a repeat order for them, how many times they has ordered before, the day and time of their order, and how many day it's been since they last ordered. 

For each product, there is information on the product name, as well as the corresponding department and aisle, both numerically (Aisle 2) and qualitatively (Specialty Cheeses, yum). 

For example, we can see that the account for User ID 79431 placed an order on Friday at 6pm for Grated Pecorino Romano Cheese;	Spring Water;	Organic Half & Half; Super Greens Salad; 	Cage Free Extra Large Grade AA Eggs; Prosciutto, Americano; Organic Garnet Sweet Potato (Yam); Asparagus, added in that order to their cart. Yay for yams! Boo for bottled water. 

There are 134 aisles, with the most popular ordered from being Aisle 83, the Fresh Vegetables aisle, with 150,609 items ordered! The second most popular aisle ordered from is the Fresh Fruits aisle, with 150,473 items ordered! Glad to see instacart users eating healthy!



Making a plot showing the number of items ordered in each aisle, for aisles with more than 10000 items ordered.
```{r}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

instacart %>%
  group_by(aisle) %>%
  count(aisle_id) %>% 
  filter(n > 10000) %>% 
  ggplot(aes(x = aisle_id, y = n, color = aisle_id)) + 
    geom_point() + labs(
      title = "Items Ordered per Grocery Aisle", 
      x = "Aisle ID",
      y = "Number of Orders") 

```


Making a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”, with the number of times each item is ordered. 

```{r}

instacart %>% 
  group_by(aisle) %>%
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle ==  "packaged vegetables fruits") %>% 
  count(product_name) %>% 
  filter(min_rank(desc(n)) < 4) %>% 
  rename("Number of orders" = n, "Product Name" = product_name, "Aisle" = aisle) %>% 
  knitr::kable(caption = "The Top 3 Items in the 3 Most Interesting Aisles")

```





Making a 2x7 table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week. 
```{r}
 
instacart %>% 
  mutate(order_dow = recode(order_dow, 
    "0" = "Sunday", 
    "1" = "Monday", "2" = "Tuesday", "3" = "Wednesday", "4" = "Thursday", "5" = "Friday", "6" = "Saturday"),
    ) %>% 
  group_by(product_name, order_dow) %>%
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>% 
  summarize(
    meanhr = mean(order_hour_of_day)
    ) %>% 
  pivot_wider(
    names_from = "order_dow",
    values_from = "meanhr"
    ) %>% 
  rename(Product = product_name) %>% 
  knitr::kable(caption = "Mean Hour (24h) of Coffee Ice Cream and Pink Lady Apple Orders") 

```



# Problem 2

Data from the Behavioral Risk Factors Surveillance System for Selected Metropolitan Area Risk Trends (SMART) for 2002-2010.
Cleaning the data:
```{r}

library(p8105.datasets)
data("brfss_smart2010")

brfss <-
  brfss_smart2010 %>% 
  janitor::clean_names(case = c("snake")) %>% 
  rename(
    state = locationabbr,
    county = locationdesc,
    estimate = data_value,
    estimate_type = data_value_type
  ) %>% 
  select(-location_id) %>% 
  group_by(topic) %>% 
  filter(response == "Excellent" | response == "Very good" | response == "Good" | response == "Fair" | response == "Poor") %>% 
  mutate(
    response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"))
  )


brfss %>% 
  group_by(year, state) %>% 
  summarize(n = n_distinct(county)) %>% 
  filter(year == 2002, n > 6) 

brfss %>% 
  group_by(year, state) %>% 
  summarize(n = n_distinct(county)) %>% 
  filter(year == 2010, n > 6) 

```

In 2002, there were 6 states that were observed at 7 or more locations, compared to 14 states in 2010. 



```{r}

excellent <- 
  brfss %>% 
  filter(response == "Excellent") %>% 
  group_by(state, year) %>% 
  mutate(
    avgest = mean(estimate),
    avgest = round(avgest, digits = 2)
  ) %>% 
  select(year, state, avgest)

ggplot(data = excellent, aes(x = year, y = avgest, group = state, colour = state)) + geom_point() + geom_line() + labs(
      x = "Year",
      y = "Average estimate") 

plot1 = 
  brfss %>% 
  group_by(response) %>% 
  filter(year == 2006, state == "NY") %>% 
  ggplot(aes(x = response, y = estimate, color = response)) + geom_boxplot() + theme(legend.position = "none")

plot2 = 
  brfss %>% 
  group_by(response) %>% 
  filter(year == 2010, state == "NY") %>% 
  ggplot(aes(x = response, y = estimate, color = response)) + geom_boxplot() + theme(legend.position = "bottom")

(plot1 + plot2)
```



# Problem 3

Loading, tidying, wrangling the data:
```{r}
"./data/accel_data.csv"

accel <- 
  read_csv("data/accel_data.csv") %>% 
  rename('dayofwk' = day, studyday = day_id) %>% 
  mutate(wkdaywkend = case_when(
      dayofwk == "Monday" ~ "weekday",
      dayofwk == "Tuesday" ~ "weekday",
      dayofwk == "Wednesday" ~ "weekday",
      dayofwk == "Thursday" ~ "weekday",
      dayofwk == "Friday" ~ "weekday",
      dayofwk == "Saturday" ~ "weekend",
      dayofwk == "Sunday" ~ "weekend"
      )) %>% 
  mutate_if(is.numeric, round, digits = 2) %>% 
  janitor::clean_names(dat = ., case = c("snake")) 

```
The accelerometer dataset contains activity data from every minute of the day for 35 days for one individual aged 63 with BMI 25. Additionally, there are variables for the day of the week, as well as whether the day was a weekend or weekday. 

```{r}

plotdata = 
  accel %>% 
  pivot_longer(activity_1:activity_1440,
              names_to = "activity_minute",
               values_to = "activity") %>% 
    group_by(studyday, dayofwk) %>% 
  summarise(daily = sum(activity))


  ggplot(data = plotdata, aes(x = studyday, y = daily, color = dayofwk)) + geom_point() + scale_x_continuous(breaks = c(7, 14, 21, 28, 35)) 

plotdata %>% 
  knitr::kable()
``` 


Based on the daily total activity data presented in the table, there don't seem to be any trends present. This man's activity fluctuates greatly, from 1440 on a Saturday to 685910 on a Monday! 


Additionally, based on the plot showing the 24-hour activity time courses for each day, there doesn't seem to be a consistent relationship between day of the week and activity. On Tuesdays, shown in purple on the plot, our guy seems to typically have the same amount of activity, but on Mondays (shown in burnt yellow) and Saturdays (shown in dark green), his activity fluctuates greatly. In particular, he had two lazy Saturdays in the 4th and 5th weeks of observation. Or, he could have forgotten to wear the accelerometer on these days. I'll choose to believe that he had lazy Saturdays and live vicariously through him. 




